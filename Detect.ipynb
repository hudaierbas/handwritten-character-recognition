{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import load_model\n",
    "\n",
    "from imutils.perspective import four_point_transform\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD TRAINED MODEL\n",
    "model = load_model('models/model_hand_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the example image and convert it to grayscale\n",
    "image = cv2.imread('test-images/5.jpg')\n",
    "#image = cv2.resize(image, (600, 400))\n",
    "\n",
    "# detect rectangle\n",
    "# pre-process the image by resizing it, converting it to\n",
    "# graycale, blurring it, and computing an edge map\n",
    "#image = imutils.resize(image, height=500)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(blurred, 50, 200, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the edge map, then sort them by their\n",
    "# size in descending order\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
    "                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "displayCnt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the contours\n",
    "for c in cnts:\n",
    "    # approximate the contour\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "    # if the contour has four vertices, then we have found\n",
    "    # the thermostat display\n",
    "    if len(approx) == 4:\n",
    "        displayCnt = approx\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the id display, apply a perspective transform\n",
    "# to it\n",
    "warped = four_point_transform(gray, displayCnt.reshape(4, 2))\n",
    "output = four_point_transform(image, displayCnt.reshape(4, 2))\n",
    "\n",
    "output = cv2.resize(output, (600, 400))\n",
    "#cropped_image = output[65:340, 55:550]\n",
    "cropped_image = output.copy()\n",
    "#cv2.imshow(\"cropped_image\", cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(output, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "gray = cv2.erode(gray, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect chars\n",
    "edged = cv2.Canny(gray, 50, 200, 255)\n",
    "\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_TREE,\n",
    "                        cv2.CHAIN_APPROX_NONE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sorted(cnts, key=cv2.contourArea, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[367, 97, 155, 233], [185, 90, 159, 230], [68, 91, 100, 233]]\n",
      "[[68, 91, 100, 233], [185, 90, 159, 230], [367, 97, 155, 233]]\n",
      "[array([[255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       ...,\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8), array([[255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       ...,\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8), array([[255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       ...,\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "drawedContours = []\n",
    "\n",
    "chars = []\n",
    "\n",
    "\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "    contour_area = cv2.contourArea(c)\n",
    "\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "    if not x in drawedContours:\n",
    "        if contour_area > 10000 and contour_area < 30000:\n",
    "            drawedContours.append(x)\n",
    "            chars.append([x, y, w, h])\n",
    "            cv2.rectangle(cropped_image, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "            cv2.putText(cropped_image, str(count), (x+20, y+20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)\n",
    "            count += 1\n",
    "\n",
    "count = 1\n",
    "print(chars)\n",
    "\n",
    "shorted_char_list = sorted(chars, key=lambda x: x[0])\n",
    "print(shorted_char_list)\n",
    "\n",
    "cropped_chars = []\n",
    "\n",
    "\n",
    "for c in shorted_char_list:\n",
    "    crop_img = gray[c[1]:c[1]+c[3], c[0]:c[0]+c[2]]\n",
    "    #cv2.imshow(\"cropped_\" + str(count), crop_img)\n",
    "    cropped_chars.append(crop_img)\n",
    "    #cv2.waitKey(0)\n",
    "    count += 1\n",
    "    \n",
    "print(cropped_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the output images\n",
    "# cv2.imshow(\"cropped_image\", cropped_image)\n",
    "# cv2.imshow(\"Image\", image)\n",
    "# cv2.imshow(\"Output\", gray)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: L\n",
      "Confidence: 1.00\n",
      "--------------------------------\n",
      "Prediction: U\n",
      "Confidence: 0.88\n",
      "--------------------------------\n",
      "Prediction: H\n",
      "Confidence: 0.90\n",
      "--------------------------------\n",
      "LUH\n"
     ]
    }
   ],
   "source": [
    "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}\n",
    "\n",
    "predicted_text = \"\"\n",
    "\n",
    "count = 1\n",
    "\n",
    "#PREDICTION ON EXTERNAL IMAGE\n",
    "for i in cropped_chars:\n",
    "    img = i\n",
    "    img_copy = img.copy()\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img = cv2.resize(img, (400,440))\n",
    "\n",
    "    img_copy = cv2.GaussianBlur(img_copy, (7,7), 0)\n",
    "    #img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
    "    #_, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "    _, img_thresh = cv2.threshold(img_copy, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "    img_final = cv2.resize(img_thresh, (28,28))\n",
    "    img_final =np.reshape(img_final, (1,28,28,1))\n",
    "\n",
    "    confidence = model.predict(img_final)\n",
    "    img_pred = word_dict[np.argmax(confidence)]\n",
    "    cv2.putText(img, \"p_\" + str(count), (20,25), cv2.FONT_HERSHEY_TRIPLEX, 0.7, color = (0,0,230))\n",
    "    cv2.putText(img, \"Confidence: \" + \"{:.2f}\".format(confidence[0][np.argmax(confidence)]), (20,380), cv2.FONT_HERSHEY_DUPLEX, 1.3, color = (255,0,30))\n",
    "    cv2.putText(img, \"Prediction: \" + img_pred, (20,200), cv2.FONT_HERSHEY_DUPLEX, 1.3, color = (255,0,0))\n",
    "    cv2.imshow(\"p_\" + str(count), img)\n",
    "    predicted_text = predicted_text + str(img_pred)\n",
    "    count +=1\n",
    "    \n",
    "    \n",
    "    print(\"Prediction: \" + img_pred)\n",
    "    print(\"Confidence: \" + \"{:.2f}\".format(confidence[0][np.argmax(confidence)]))\n",
    "    print(\"--------------------------------\")\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "\n",
    "print(predicted_text)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
